{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/metaswang/asr_notebook/blob/main/%E2%80%9Cwhisper_transcription_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=64px>Whisper Transcription</font>\n",
        "\n",
        "Notebook built by Trelis Research. Find us at [Trelis.com](https://trelis.com), on [YouTube](https://YouTube.com/@TrelisResearch) and on [HuggingFace](https://huggingface.co/Trelis).\n",
        "\n",
        "*Trelis Research emails members each time a new video tutorial is published. If you'd like, you can join [here](https://trelis.substack.com).*\n",
        "\n",
        "Built upon an [original notebook](https://colab.research.google.com/github/deepgram-devs/try-whisper-in-google-collab/blob/main/try_whisper_in_three_easy_steps.ipynb) by Ross O'Connell."
      ],
      "metadata": {
        "id": "9qzwD9ts4_kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive (optional)\n",
        "You also need to change the paths below for pulling and transcribing audio."
      ],
      "metadata": {
        "id": "biPhaxG7LHPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_KKivchsPXCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "cache_dir = \"/content/drive/My Drive/video_transcripts\"\n",
        "os.makedirs(cache_dir, exist_ok=True) # Ensure the directory exists"
      ],
      "metadata": {
        "id": "XdeaEucBPYim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Whisper"
      ],
      "metadata": {
        "id": "tATxgEBmLK_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first line we install Whisper! (see [HuggingFace](https://huggingface.co/openai/whisper-small) for more details)"
      ],
      "metadata": {
        "id": "V1QHcVQz4Gu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "smi7rndyMp6Y",
        "outputId": "88b7b59c-dbe9-4c11-e375-4cc127a31a0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.45-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Installing collected packages: importlib_metadata, fastavro, backoff, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.45 fastavro-1.9.3 importlib_metadata-6.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "rZRwYRVPMshQ",
        "outputId": "0b2bc9a8-596d-4f42-99d3-76b1052f10ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.11.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.11.0 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOvKw2K3kWqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bcf251-c8a4-40c5-9a75-c43a854f2766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q -U"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grab and transcribe some audio from YouTube"
      ],
      "metadata": {
        "id": "FatSKi3YAQCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt-dlp -q -U"
      ],
      "metadata": {
        "id": "0NqzXPOXQ6JQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c885b6-9f0f-48a5-b853-058324dc0df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !yt-dlp https://youtu.be/oZ0i_JMeV8s?si=azrU_vo2On6aOaP2 --format m4a -o \"/content/%(id)s.%(ext)s\"\n",
        "!whisper \"/content/oZ0i_JMeV8s.m4a\" --model small --language Chinese"
      ],
      "metadata": {
        "id": "cYaGfY1J2VRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19baa9b7-87fa-40e2-ba2b-db2c16b3ee88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:03.800] 我是林医师 我是来征尊科医师\n",
            "[00:03.800 --> 00:06.000] 那今天到了茶室来\n",
            "[00:06.000 --> 00:11.000] 那么我原来是感觉到我的腰腿\n",
            "[00:11.000 --> 00:13.000] 它有疼痛\n",
            "[00:13.000 --> 00:15.700] 那么我也吃了中药一阵子以后呢\n",
            "[00:15.700 --> 00:19.300] 发现改善的情况并不是很理想\n",
            "[00:19.300 --> 00:23.500] 那么之前因为我跟这个吴老师是旧事\n",
            "[00:23.500 --> 00:29.900] 那么也知道他这些茶是非常有功效的\n",
            "[00:29.900 --> 00:33.800] 所以我来之前我就心里在想说\n",
            "[00:33.800 --> 00:36.200] 既然用中药的疗法\n",
            "[00:36.200 --> 00:38.000] 那么也经过一段时间\n",
            "[00:38.000 --> 00:41.400] 那我自己也休息了几天这样子下来\n",
            "[00:41.400 --> 00:46.300] 我感觉上就说它的这个情况\n",
            "[00:46.300 --> 00:48.500] 并没有有很显著的改善\n",
            "[00:48.500 --> 00:50.400] 所以今天到这边来\n",
            "[00:50.400 --> 00:53.200] 那么跟吴老师在聊的时候\n",
            "[00:53.200 --> 00:54.600] 他针对我的症状\n",
            "[00:54.600 --> 00:58.400] 那么就给我泡了一壶茶\n",
            "[00:58.400 --> 00:59.800] 我们在这边共享\n",
            "[00:59.800 --> 01:01.300] 那前后呢\n",
            "[01:01.300 --> 01:03.300] 大概说半小时左右的时间\n",
            "[01:03.300 --> 01:04.300] 我跟他边聊\n",
            "[01:04.300 --> 01:06.500] 然后边讲也边喝茶\n",
            "[01:06.500 --> 01:07.100] 他发现说\n",
            "[01:07.100 --> 01:09.500] 这个症状真的是\n",
            "[01:09.500 --> 01:11.100] 尤其是疼痛的部分\n",
            "[01:11.100 --> 01:17.700] 有改善了他的这个渐缓的这个情况发生\n",
            "[01:17.700 --> 01:21.600] 所以我想这个是我个人一个感受\n",
            "[01:21.600 --> 01:25.000] 因为个人的身体状况只有自己能感受得到\n",
            "[01:25.000 --> 01:27.400] 所以我要把这个心得\n",
            "[01:27.400 --> 01:28.600] 跟各位分享一下\n",
            "[01:28.600 --> 01:30.600] 那么让大家知道说\n",
            "[01:30.600 --> 01:34.100] 的确我在我身上是有这样子的一个效果\n",
            "[01:34.100 --> 01:34.600] 谢谢\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grab an audio file you have uploaded to Colab\n",
        "Click the folder icon in the left hand toolbar, and upload your audio file in m4a or mp3."
      ],
      "metadata": {
        "id": "hnZOa4A4O1rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/llm-lingo.m4a\" --model small --language English"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYtbcHCPPD6j",
        "outputId": "a7d3e148-f98a-4cc0-be13-c4d0569def50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:09<00:00, 49.0MiB/s]\n",
            "[00:00.000 --> 00:05.000]  PHY2 gets an MIT license.\n",
            "[00:05.000 --> 00:08.000]  Lightning Attention 2.\n",
            "[00:08.000 --> 00:14.000]  It's the first linear implementation for attention computation.\n",
            "[00:14.000 --> 00:19.000]  A technical report on mixed trial 8x7B.\n",
            "[00:19.000 --> 00:28.000]  KPO, DPO and IPO.\n",
            "[00:28.000 --> 00:32.000]  Direct preference optimization.\n",
            "[00:32.000 --> 00:36.000]  Solar 10.7B.\n",
            "[00:36.000 --> 00:43.000]  This involves adding layers from a mixed trial 7B to a mixed trial 7B model.\n",
            "[00:43.000 --> 00:45.000]  OpenChat.\n",
            "[00:45.000 --> 00:53.000]  One of the very best LLMs that does not use preference optimization.\n",
            "[00:53.000 --> 00:58.000]  Noteux 8x7B V1.\n",
            "[00:58.000 --> 01:04.000]  This is a model that uses DPO on top of more DPO.\n",
            "[01:04.000 --> 01:11.000]  Gemini Pro versus GPT 3.5.\n",
            "[01:11.000 --> 01:14.000]  Microsoft PHY2.\n",
            "[01:14.000 --> 01:18.000]  A better and stronger model than PHY1.5.\n",
            "[01:18.000 --> 01:20.000]  Desi LM7B.\n",
            "[01:20.000 --> 01:24.000]  A very fast 7 billion parameter model.\n",
            "[01:24.000 --> 01:27.000]  Spin SPIN.\n",
            "[01:27.000 --> 01:31.000]  Self play fine tuning that improves LLMs.\n",
            "[01:31.000 --> 01:33.000]  Trixie.\n",
            "[01:33.000 --> 01:38.000]  Which is fast inference involving sparsity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running one of the above cells, you'll find the transcript (a vtt file) in your folder."
      ],
      "metadata": {
        "id": "XBzQvdWbWch2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "biPhaxG7LHPj",
        "qOtm7PV0WwR3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}